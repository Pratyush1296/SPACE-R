{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_is = pd.read_pickle('C:/Users/Pratyush Yadav/Desktop/IITM/Research/IPM Exp/WoS_IS/for_author_details.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_info1[author_info1['Author_name_actual'].str.contains(\"Iacob\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For getting the list stored as a string in csv files\n",
    "# import ast\n",
    "# list1=ast.literal_eval(wos_covid['Authors'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wos_is.columns = ['UT (Unique WOS ID)','Title','Abstract','Authors','Author Full Names','Addresses','Publication Year',\n",
    "                  'Venue','references','n_citations','Times Cited, All Databases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wos_is['Author Full Names'] = wos_is['Author Full Names'].fillna('')\n",
    "wos_is['Authors'] = wos_is['Authors'].fillna('')\n",
    "wos_is['Addresses'] = wos_is['Addresses'].fillna('')\n",
    "wos_is['Publication Year'] = wos_is['Publication Year'].fillna(0)\n",
    "# wos_covid['Publication Date'] = wos_covid['Publication Date'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_is['Times Cited, All Databases'] = wos_is['Times Cited, All Databases'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source=[]\n",
    "target=[]\n",
    "source_s=[]\n",
    "target_s=[]\n",
    "year=[]\n",
    "# date=[]\n",
    "paper_id=[]\n",
    "paper_cite=[]\n",
    "for i in range(len(wos_is)):\n",
    "    author1=[]\n",
    "    author1_short=[]\n",
    "    for j in range(len(wos_is['Author Full Names'][i])):\n",
    "        author1_short.append(wos_is['Authors'][i][j])\n",
    "        author1.append(wos_is['Author Full Names'][i][j])\n",
    "    for k in combinations(author1,2):\n",
    "        source.append(k[0])\n",
    "        target.append(k[1])\n",
    "    for k in combinations(author1_short,2):\n",
    "        source_s.append(k[0])\n",
    "        target_s.append(k[1])\n",
    "        year.append(wos_is['Publication Year'][i])\n",
    "#         date.append(wos_covid1['Publication Date'][i])\n",
    "        paper_id.append(wos_is['UT (Unique WOS ID)'][i])\n",
    "        paper_cite.append(wos_is['Times Cited, All Databases'][i])\n",
    "count = np.ones(len(source))\n",
    "\n",
    "author_ini = pd.DataFrame({\n",
    "    'Source':source,\n",
    "    'Target':target,\n",
    "    'weight':count,\n",
    "    'Source_short':source_s,\n",
    "    'Target_short':target_s,\n",
    "    'year':year,\n",
    "#     'date':date,\n",
    "    'paper_id':paper_id,\n",
    "    'cite':paper_cite\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author Disambiguation - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_name_proc(name):\n",
    "    name = name.strip()\n",
    "    if ',' in name:\n",
    "        author_proc_name=name.split(',')[1].strip()+'_'+name.split(',')[0].strip()\n",
    "    elif '-' in name:\n",
    "        author_proc_name=name.split('-')[1].strip()+'_'+name.split('-')[0].strip()\n",
    "    else:\n",
    "        if len(name.split(' '))!=1:\n",
    "            author_proc_name= name.split(' ')[1].strip()+'_'+name.split(' ')[0].strip()\n",
    "        else:\n",
    "            author_proc_name= name\n",
    "    return author_proc_name\n",
    "\n",
    "author_ini['Source_proc']=author_ini['Source'].apply(lambda x: author_name_proc(x))\n",
    "author_ini['Target_proc']=author_ini['Target'].apply(lambda x: author_name_proc(x))\n",
    "author_ini['Source_short_proc']=author_ini['Source_short'].apply(lambda x: author_name_proc(x))\n",
    "author_ini['Target_short_proc']=author_ini['Target_short'].apply(lambda x: author_name_proc(x))\n",
    "author_name_list=list(set(author_ini['Source_proc']).union(set(author_ini['Target_proc'])))\n",
    "author_short_names = list(set(author_ini['Source_short_proc']).union(set(author_ini['Target_short_proc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors=[]\n",
    "authors_short=[]\n",
    "year=[]\n",
    "# date=[]\n",
    "paper_id=[]\n",
    "paper_cite=[]\n",
    "for i in range(len(wos_is)):\n",
    "    for j in range(len(wos_is['Author Full Names'][i])):\n",
    "        authors.append(wos_is['Author Full Names'][i][j])\n",
    "        authors_short.append(wos_is['Authors'][i][j])\n",
    "        year.append(wos_is['Publication Year'][i])\n",
    "#         date.append(wos_covid1['Publication Date'][i])\n",
    "        paper_id.append(wos_is['UT (Unique WOS ID)'][i])\n",
    "        paper_cite.append(wos_is['Times Cited, All Databases'][i])\n",
    "author_full = pd.DataFrame({\n",
    "    'Author_name':authors,\n",
    "    'Author_name_short':authors_short,\n",
    "    'Year':year,\n",
    "#     'Date':date,\n",
    "    'paper_id':paper_id,\n",
    "    'cite':paper_cite\n",
    "})\n",
    "author_full['Author_name1']=author_full['Author_name'].apply(lambda x: author_name_proc(x))\n",
    "author_full['Author_name_short1']=author_full['Author_name_short'].apply(lambda x: author_name_proc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_name_list=author_full['Author_name1'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(author_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "author_name_short=[]\n",
    "publications=[]\n",
    "citations=[]\n",
    "for i in range(len(author_name_list)):\n",
    "    author_df = author_full[author_full['Author_name1']==author_name_list[i]]\n",
    "    papers = author_df['paper_id'].unique().tolist()\n",
    "    publications.append(len(papers))\n",
    "    citations.append(sum(wos_is[wos_is['UT (Unique WOS ID)'].isin(papers)]\n",
    "                         ['Times Cited, All Databases'].tolist()))\n",
    "    author_name_short.append(author_df['Author_name_short1'].tolist()[0])\n",
    "    print(i)\n",
    "    \n",
    "author_info1 = pd.DataFrame({\n",
    "    'Author_name_actual':author_name_list,\n",
    "    'Author_short_name':author_name_short,\n",
    "    'Pub_count':publications,\n",
    "    'Cite_count':citations\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_is['Authors'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(wos_is['Addresses'][2])):\n",
    "    print(wos_is['Addresses'][2][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_is['Authors'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wos_is)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### affiliations and years\n",
    "# authors=[]\n",
    "# affil=[]\n",
    "# year=[]\n",
    "# for i in range(len(wos_is)):\n",
    "#     if wos_is['Addresses'][i]!='':\n",
    "#         try:\n",
    "#             for j in wos_is['Addresses'][i].items():\n",
    "#                 authors.append(j[0])\n",
    "#                 affil.append(j[1][0])\n",
    "#                 year.append(wos_is['Publication Year'][i])\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "# author_affil=pd.DataFrame({\n",
    "#     'Author_name':authors,\n",
    "#     'Affiliation':affil,\n",
    "#     'Year':year\n",
    "# })\n",
    "# author_affil['Author_name1'] = author_affil['Author_name'].apply(lambda x: author_name_proc(x))\n",
    "\n",
    "authors=[]\n",
    "year=[]\n",
    "for i in range(len(wos_is)):\n",
    "    for j in range(len(wos_is['Author Full Names'][i])):\n",
    "        authors.append(wos_is['Author Full Names'][i][j])\n",
    "        year.append(wos_is['Publication Year'][i])\n",
    "author_affil=pd.DataFrame({\n",
    "    'Author_name':authors,\n",
    "    'Year':year\n",
    "})\n",
    "author_affil['Author_name1'] = author_affil['Author_name'].apply(lambda x: author_name_proc(x))\n",
    "        \n",
    "        \n",
    "\n",
    "# most_or_rec_affil=[]\n",
    "recent_year=[]\n",
    "old_year=[]\n",
    "for i in range(len(author_info1)):\n",
    "    author_name = author_info1['Author_name_actual'][i]\n",
    "    affil_auth = author_affil[author_affil['Author_name1']==author_name]\n",
    "    year_list=affil_auth['Year'].unique().tolist()\n",
    "    if len(year_list)!=0:\n",
    "        recent_year.append(sorted(year_list,reverse=True)[0])\n",
    "        old_year.append(sorted(year_list,reverse=False)[0])\n",
    "    else:\n",
    "        recent_year.append(sorted(author_ini[(author_ini['Source_proc']==author_name)|\n",
    "                                             (author_ini['Target_proc']==author_name)]['year'].unique().tolist(),reverse=True)[0])\n",
    "        old_year.append(sorted(author_ini[(author_ini['Source_proc']==author_name)|\n",
    "                                             (author_ini['Target_proc']==author_name)]['year'].unique().tolist(),reverse=False)[0])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_auth=[]\n",
    "for i in range(len(author_info1)):\n",
    "    author_name_co = author_info1['Author_name_actual'][i]\n",
    "    papers = author_full[author_full['Author_name1']==author_name_co]['paper_id'].unique().tolist()\n",
    "    auth_set = author_full[author_full['paper_id'].isin(papers)]['Author_name1'].unique().tolist()\n",
    "    co_auth1 = [i for i in auth_set if i!=author_name_co]\n",
    "    co_auth.append(co_auth1)\n",
    "    print(i)\n",
    "#author_info['coauthors']=co_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_info1['year']=recent_year\n",
    "author_info1['coauthors']=co_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(author_info1)):\n",
    "    author_info1.loc[i,'affil']=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install disamby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import persons\n",
    "import disamby.preprocessors as pre\n",
    "from disamby import Disamby\n",
    "pipeline = [\n",
    "    pre.normalize_whitespace,\n",
    "    pre.remove_punctuation,\n",
    "    lambda x: pre.trigram(x) + pre.split_words(x)  # any python function is allowed\n",
    "]\n",
    "nm = persons.Persons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch=['.','?']\n",
    "def replace_punct(str2):\n",
    "    for c in ch:\n",
    "        str2 = str2.replace(c,\"\")\n",
    "    str2 = str2.replace(\"-\",\" \")\n",
    "    return str2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_info1['Author_first_name']=author_info1['Author_name_actual'].apply(lambda x: x.split(\"_\")[0] if \"_\" in x else x)\n",
    "author_info1['Author_last_name']=author_info1['Author_name_actual'].apply(lambda x: x.split(\"_\")[1] if \"_\" in x else x)\n",
    "author_info1['Author_fnm']=author_info1['Author_first_name'].apply(lambda x: replace_punct(x))\n",
    "author_info1['Author_fnm']=author_info1['Author_fnm'].apply(lambda x: ('. ').join(list(x.replace(\" \",\"\")))+\".\" if x.isupper() else x)\n",
    "author_info1['Author_lnm']=author_info1['Author_last_name'].apply(lambda x: ('').join(re.sub(r\"[\\-]\",\" \",x).split(\" \")).title())\n",
    "author_info1['affil1']=author_info1['affil'].apply(lambda x: x.split(',')[0])\n",
    "author_info1['country'] = author_info1['affil'].apply(lambda x: x.split(',')[-1].split(' ')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_disamby = author_info1[['Author_fnm','Author_lnm','Author_short_name','affil1']]\n",
    "author_disamby.columns = ['author_first_name','author_last_name','author_short','affil1']\n",
    "result = nm.persons_from_names(author_disamby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnms_proc=author_info1['Author_lnm'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lnms_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id1=[]\n",
    "name=[]\n",
    "for k in range(len(lnms_proc)):\n",
    "    author1 = author_info1[author_info1['Author_lnm']==lnms_proc[k]]\n",
    "    author1.index = range(len(author1))\n",
    "#     author_info1.fillna(\"\",inplace=True)\n",
    "    count = []\n",
    "    for i in range(len(author1)):\n",
    "        for j in range(i,len(author1)):\n",
    "            if i!=j:\n",
    "                sname1 = author1['Author_short_name'][i]\n",
    "                sname2 = author1['Author_short_name'][j]\n",
    "                fname1 = author1['Author_fnm'][i]\n",
    "                fname2 = author1['Author_fnm'][j]\n",
    "                lname1 = author1['Author_lnm'][i]\n",
    "                lname2 = author1['Author_lnm'][j]\n",
    "                affil1 = author1['affil1'][i].split(',')[0]\n",
    "                affil2 = author1['affil1'][j].split(',')[0]\n",
    "                year1 = author1['year'][i]\n",
    "                year2 = author1['year'][j]\n",
    "                if sname1 == sname2:\n",
    "                    if affil1!='' and affil2!='':\n",
    "                        if (affil1 in affil2) or (affil2 in affil1):\n",
    "                                if (fname1 in fname2) or (fname2 in fname1):\n",
    "                                    count.append((i,j))\n",
    "                                elif \".\" in fname1.split(\" \")[0]:\n",
    "                                    if \".\" in fname2.split(\" \")[0]:\n",
    "                                        if fname1.split(\" \")[0].split(\".\")[0] == fname2.split(\" \")[0].split(\".\")[0]:\n",
    "                                                count.append((i,j))\n",
    "                                    else:\n",
    "                                        if fname1.split(\" \")[0].split(\".\")[0] == list(fname2.split(\" \")[0])[0]:\n",
    "                                            count.append((i,j))\n",
    "                                elif \".\" in fname2.split(\" \")[0]:\n",
    "                                    if list(fname1.split(\" \")[0])[0] == fname2.split(\" \")[0].split(\".\")[0]:\n",
    "                                        count.append((i,j))\n",
    "                                else:\n",
    "                                    count1=0\n",
    "                                    if len(fname2)>len(fname1):\n",
    "                                        for l in range(len(fname1)):\n",
    "                                            if fname1[l] in fname2:\n",
    "                                                count1 = count1+1\n",
    "                                        if count1>=len(fname1):\n",
    "                                            count.append((i,j))\n",
    "                                    else:\n",
    "                                        for l in range(len(fname2)):\n",
    "                                            if fname2[l] in fname1:\n",
    "                                                count1 = count1+1\n",
    "                                        if count1>=len(fname2):\n",
    "                                            count.append((i,j))\n",
    "                        else:\n",
    "                            if year1!=year2 and year1!=\"\" and year2!=\"\":\n",
    "                                if fname1==fname2:\n",
    "                                    count.append((i,j))\n",
    "                                elif fname1.split(\" \")[0] == fname2.split(\" \")[0]:\n",
    "                                    count.append((i,j))\n",
    "                                else:\n",
    "                                    if \".\" in fname1.split(\" \")[0]:\n",
    "                                        if \".\" in fname2.split(\" \")[0]:\n",
    "                                            if fname1.split(\" \")[0].split(\".\")[0] == fname2.split(\" \")[0].split(\".\")[0]:\n",
    "                                                count.append((i,j))\n",
    "                                        else:\n",
    "                                            if fname1.split(\" \")[0].split(\".\")[0] == list(fname2.split(\" \")[0])[0]:\n",
    "                                                count.append((i,j))\n",
    "                                    else:\n",
    "                                        if \".\" in fname2.split(\" \")[0]:\n",
    "                                            if list(fname1.split(\" \")[0])[0] == fname2.split(\" \")[0].split(\".\")[0]:\n",
    "                                                count.append((i,j))\n",
    "                else:\n",
    "                    if lname1 == lname2:\n",
    "                        if fname1.split(\" \")[0] == fname2.split(\" \")[0]:\n",
    "                            if affil1!=\"\" and affil2!=\"\":\n",
    "                                if (affil1 in affil2) or (affil2 in affil1):\n",
    "                                    count.append((i,j))\n",
    "                                    \n",
    "    counter=0\n",
    "    for i in range(len(author1)):\n",
    "        flag=0\n",
    "        if counter==0:\n",
    "            for j in range(counter,len(count)):\n",
    "                if i in count[j]:\n",
    "                    counter= counter+1\n",
    "                    flag= flag+1\n",
    "                    name1 = author1['Author_fnm'][count[j][0]]+'_'+author1['Author_lnm'][count[j][0]]\n",
    "                    name2 = author1['Author_fnm'][count[j][1]]+'_'+author1['Author_lnm'][count[j][1]]\n",
    "                    if name1 not in name:\n",
    "                        name.append(name1)\n",
    "                        id1.append(1)\n",
    "                    if (name2 not in name):\n",
    "                        name.append(name2)\n",
    "                        id1.append(0)\n",
    "        else:\n",
    "            for j in range(counter-1,len(count)):\n",
    "                if i in count[j]:\n",
    "                    counter= counter+1\n",
    "                    flag= flag+1\n",
    "                    name1 = author1['Author_fnm'][count[j][0]]+'_'+author1['Author_lnm'][count[j][0]]\n",
    "                    name2 = author1['Author_fnm'][count[j][1]]+'_'+author1['Author_lnm'][count[j][1]]\n",
    "                    if name1 not in name:\n",
    "                        name.append(name1)\n",
    "                        id1.append(1)\n",
    "                    if (name2 not in name):\n",
    "                        name.append(name2)\n",
    "                        id1.append(0)\n",
    "\n",
    "\n",
    "        if flag==0:\n",
    "            name1 = author1['Author_fnm'][i]+'_'+author1['Author_lnm'][i]\n",
    "            if name1 not in name:\n",
    "                name.append(name1)\n",
    "                id1.append(1)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(name)):\n",
    "    fnm = name[i].split('_')[0]\n",
    "    snm = name[i].split('_')[1]\n",
    "    result.loc[result[(result['author_first_name']==fnm)&(result['author_last_name']==snm)].index.tolist(),'algo1']=sum(id1[:i+1])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_co=[]\n",
    "name_co=[]\n",
    "for k in range(len(lnms_proc)):\n",
    "    author2=author_info1[author_info1['Author_lnm']==lnms_proc[k]]\n",
    "    author2=author2.reset_index()\n",
    "    count=[]\n",
    "    for i in range(len(author2)):\n",
    "        for j in range(i,len(author2)):\n",
    "            if i!=j:\n",
    "                names1 = author2['coauthors'][i]\n",
    "                names2 = author2['coauthors'][j]\n",
    "                if (len(names1)!=0) or len(names2)!=0:\n",
    "                    if jaccard_similarity(names1,names2)>0.5:\n",
    "                        count.append((i,j))\n",
    "    counter=0\n",
    "    for i in range(len(author2)):\n",
    "        flag=0\n",
    "        if counter==0:\n",
    "            for j in range(counter,len(count)):\n",
    "                if i in count[j]:\n",
    "                    counter= counter+1\n",
    "                    flag= flag+1\n",
    "                    name1 = author2['Author_fnm'][count[j][0]]+'_'+author2['Author_lnm'][count[j][0]]\n",
    "                    name2 = author2['Author_fnm'][count[j][1]]+'_'+author2['Author_lnm'][count[j][1]]\n",
    "                    if name1 not in name_co:\n",
    "                        name_co.append(name1)\n",
    "                        id_co.append(1)\n",
    "                    if (name2 not in name_co):\n",
    "                        name_co.append(name2)\n",
    "                        id_co.append(0)\n",
    "        else:\n",
    "            for j in range(counter-1,len(count)):\n",
    "                if i in count[j]:\n",
    "                    counter= counter+1\n",
    "                    flag= flag+1\n",
    "                    name1 = author2['Author_fnm'][count[j][0]]+'_'+author2['Author_lnm'][count[j][0]]\n",
    "                    name2 = author2['Author_fnm'][count[j][1]]+'_'+author2['Author_lnm'][count[j][1]]\n",
    "                    if name1 not in name_co:\n",
    "                        name_co.append(name1)\n",
    "                        id_co.append(1)\n",
    "                    if (name2 not in name_co):\n",
    "                        name_co.append(name2)\n",
    "                        id_co.append(0)\n",
    "\n",
    "\n",
    "        if flag==0:\n",
    "            name1 = author2['Author_fnm'][i]+'_'+author2['Author_lnm'][i]\n",
    "            if name1 not in name_co:\n",
    "                name_co.append(name1)\n",
    "                id_co.append(1)\n",
    "            \n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(name_co)):\n",
    "    fnm = name_co[i].split('_')[0]\n",
    "    snm = name_co[i].split('_')[1]\n",
    "    result.loc[result[(result['author_first_name']==fnm)&(result['author_last_name']==snm)].index.tolist(),'algo_co']=sum(id_co[:i+1])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list1=[]\n",
    "for i in range(len(lnms_proc)):\n",
    "    author_disam1 = author_info1[author_info1['Author_lnm']==lnms_proc[i]][['Author_fnm','Author_short_name','affil1','country']]\n",
    "    dis = Disamby(author_disam1,pipeline)\n",
    "    list1.append(dis.disambiguated_sets(verbose=False))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.reset_index(inplace=True)\n",
    "# result.set_index('name_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_author=0\n",
    "for i in range(len(list1)):\n",
    "    for j in range(len(list1[i])):\n",
    "        for k in range(len(list1[i][j])):\n",
    "            result.loc[list(list1[i][j])[k],'algo_dis'] = count_author\n",
    "        count_author = count_author + 1\n",
    "    print(i)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.reset_index(inplace=True)\n",
    "# result.set_index('index',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Author ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_f=[]\n",
    "name_f=[]\n",
    "for k in range(len(lnms_proc)):\n",
    "    author_f = result[result['author_last_name']==lnms_proc[k]]\n",
    "    author_f.index = range(len(author_f))\n",
    "    count=[]\n",
    "    for i in range(len(author_f)):\n",
    "        for j in range(i,len(author_f)):\n",
    "            count1=0\n",
    "            if i!=j:\n",
    "                p_id1 = author_f['person_id'][i]\n",
    "                p_id2 = author_f['person_id'][j]\n",
    "                al1_id1 = author_f['algo1'][i]\n",
    "                al1_id2 = author_f['algo1'][j]\n",
    "                alco_id1 = author_f['algo_co'][i]\n",
    "                alco_id2 = author_f['algo_co'][j]\n",
    "                al2_id1 = author_f['algo_dis'][i]\n",
    "                al2_id2 = author_f['algo_dis'][j]\n",
    "                if p_id1 == p_id2:\n",
    "                    count1 = count1+1\n",
    "                if al1_id1 == al1_id2:\n",
    "                    count1 = count1+1\n",
    "                if alco_id1 == alco_id2:\n",
    "                    count1 = count1+1\n",
    "                if al2_id1 == al2_id2:\n",
    "                    count1 = count1+1\n",
    "            if count1>=2:\n",
    "                count.append((i,j))\n",
    "    counter=0\n",
    "    for i in range(len(author_f)):\n",
    "        flag=0\n",
    "        if counter==0:\n",
    "            for j in range(counter,len(count)):\n",
    "                if i in count[j]:\n",
    "                    counter= counter+1\n",
    "                    flag= flag+1\n",
    "                    name1 = author_f['author_first_name'][count[j][0]]+'_'+author_f['author_last_name'][count[j][0]]\n",
    "                    name2 = author_f['author_first_name'][count[j][1]]+'_'+author_f['author_last_name'][count[j][1]]\n",
    "                    if name1 not in name_f:\n",
    "                        name_f.append(name1)\n",
    "                        id_f.append(1)\n",
    "                    if (name2 not in name_f):\n",
    "                        name_f.append(name2)\n",
    "                        id_f.append(0)\n",
    "        else:\n",
    "            for j in range(counter-1,len(count)):\n",
    "                if i in count[j]:\n",
    "                    counter= counter+1\n",
    "                    flag= flag+1\n",
    "                    name1 = author_f['author_first_name'][count[j][0]]+'_'+author_f['author_last_name'][count[j][0]]\n",
    "                    name2 = author_f['author_first_name'][count[j][1]]+'_'+author_f['author_last_name'][count[j][1]]\n",
    "                    if name1 not in name_f:\n",
    "                        name_f.append(name1)\n",
    "                        id_f.append(1)\n",
    "                    if (name2 not in name_f):\n",
    "                        name_f.append(name2)\n",
    "                        id_f.append(0)\n",
    "\n",
    "\n",
    "        if flag==0:\n",
    "            name1 = author_f['author_first_name'][i]+'_'+author_f['author_last_name'][i]\n",
    "            if name1 not in name_f:\n",
    "                name_f.append(name1)\n",
    "                id_f.append(1)\n",
    "            \n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(name_f)):\n",
    "    fnm = name_f[i].split('_')[0]\n",
    "    snm = name_f[i].split('_')[1]\n",
    "    result.loc[result[(result['author_first_name']==fnm)&(result['author_last_name']==snm)].index.tolist(),'final_id']=sum(id_f[:i+1])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result#['name_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_id=[]\n",
    "for i in range(len(author_info1)):\n",
    "    final_id.append(result[result['name_id']==i]['final_id'].tolist()[0])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(s):\n",
    "    return max(s, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_info1[author_info1['country']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "author_info1[author_info1['final_id']=='5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_info1[author_info1['final_id']=='1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(author_info1)):\n",
    "    cit1=author_full[author_full['Author_name1']==author_info1['Author_name_actual'][i]].index.tolist()\n",
    "    for j in range(len(cit1)):\n",
    "        author_full.loc[author_full.index[cit1[j]],'Author_ID'] = author_info1['final_id'][i]\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper_map=author_full[['paper_id','Author_ID','cite','Author_name']]\n",
    "author_paper_map.columns = ['Paper_ID','Author_ID','cite','Author_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper_map.to_pickle('C:/Users/Pratyush Yadav/Desktop/IITM/Research/IPM Exp/WoS_IS/auth2paper_wos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_info1['final_id']= final_id\n",
    "author_info1['final_id'] = author_info1['final_id'].apply(lambda x: str(x).split('.')[0])\n",
    "author_info3=author_info1.groupby('final_id').agg({'Pub_count':'sum',\n",
    "                                                   'Cite_count':'sum',\n",
    "                                                  'Author_name_actual':f1})\n",
    "author_info3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# author_ini2 = author_ini[['Source_proc','Target_proc','weight','paper_id','cite','year']]\n",
    "for i in range(len(author_info1)):\n",
    "    author_ini.loc[author_ini[author_ini['Source_proc']==\n",
    "                            author_info1['Author_name_actual'][i]].index.tolist(),\n",
    "                    'source_id'] = author_info1['final_id'][i]\n",
    "    author_ini.loc[author_ini[author_ini['Target_proc']==\n",
    "                            author_info1['Author_name_actual'][i]].index.tolist(),\n",
    "                    'target_id'] = author_info1['final_id'][i]\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_info1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_ini2=author_ini[[\"source_id\",\"target_id\",\"weight\"]]\n",
    "# author_ini2.columns = [\"Author1\",\"Author2\",\"Collaboration Number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_ini2['Source']=author_ini2[['source_id','target_id']].min(axis=1)\n",
    "author_ini2['Target']=author_ini2[['source_id','target_id']].max(axis=1)\n",
    "author_net=author_ini2.groupby(['Source','Target'],as_index=False).agg({'weight':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_net['Source'] = author_net['Source'].apply(lambda x: str(x).split('.')[0])\n",
    "author_net['Target'] = author_net['Target'].apply(lambda x: str(x).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save author_network file\n",
    "author_net.to_pickle('C:/Users/Pratyush Yadav/Desktop/IITM/Research/IPM Exp/WoS_IS/wos_is_collab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(result)):\n",
    "    fnm = result['author_first_name'][i]\n",
    "    snm = result['author_last_name'][i]\n",
    "    auth1 = author_full[(author_full['Author_fnm']==fnm)&(author_full['Author_lnm']==snm)].index.tolist()\n",
    "    author_full.loc[auth1,'final_id'] = str(result['final_id'][i]).split('.')[0]\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_full['Author_first_name']=author_full['Author_name1'].apply(lambda x: x.split(\"_\")[0] if \"_\" in x else x)\n",
    "author_full['Author_last_name']=author_full['Author_name1'].apply(lambda x: x.split(\"_\")[1] if \"_\" in x else x)\n",
    "author_full['Author_fnm']=author_full['Author_first_name'].apply(lambda x: replace_punct(x))\n",
    "author_full['Author_fnm']=author_full['Author_fnm'].apply(lambda x: ('. ').join(list(x.replace(\" \",\"\")))+\".\" if x.isupper() else x)\n",
    "author_full['Author_lnm']=author_full['Author_last_name'].apply(lambda x: ('').join(re.sub(r\"[\\-]\",\" \",x).split(\" \")).title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(author_info1)):\n",
    "    cit1=author_full[author_full['Author_name1']==author_info1['Author_name_actual'][i]].index.tolist()\n",
    "    for j in range(len(cit1)):\n",
    "        author_full.loc[author_full.index[cit1[j]],'Author_ID'] = author_info1['final_id'][i]\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pickle('C:/Users/Pratyush Yadav/Desktop/IITM/Research/IPM Exp/WoS_IS/wos_is_author_ids.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_full.to_pickle('C:/Users/Pratyush Yadav/Desktop/IITM/Research/IPM Exp/WoS_IS/auth2paper_wos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_full = author_full[['paper_id', 'final_id', 'Author_name','Author_name1']]\n",
    "author_full.columns = ['Paper_ID','Author_ID','Author_name_processed','Author_name_default']\n",
    "author_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_full['final_id'].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
